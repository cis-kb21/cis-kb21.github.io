{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "656953c21547a91cfb2057a5cd28b058012b7084abb49e89974147a4ece772c4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pip in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (21.1.3)\n",
      "Requirement already satisfied: nltk in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (3.6.2)\n",
      "Requirement already satisfied: click in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: joblib in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (from nltk) (4.61.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (from click->nltk) (4.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.4.1)\n",
      "Requirement already satisfied: pip in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (21.1.3)\n",
      "Requirement already satisfied: treetaggerwrapper in /home/flo/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages (2.3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip nltk\n",
    "!{sys.executable} -m pip install --upgrade pip treetaggerwrapper\n",
    "import nltk\n",
    "import treetaggerwrapper as TTW \n",
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "import logging \n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "ns = {'tc': \"http://www.dspin.de/data/textcorpus\"}\n",
    "urls = [\n",
    "    'https://www.deutschestextarchiv.de/book/download_fulltcf/16377',\n",
    "    'https://www.deutschestextarchiv.de/book/download_fulltcf/16178',\n",
    "    'https://www.deutschestextarchiv.de/book/download_fulltcf/25157',\n",
    "    'https://www.deutschestextarchiv.de/book/download_fulltcf/16552',\n",
    "    'https://www.deutschestextarchiv.de/book/download_fulltcf/16299',\n",
    "]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_from_tcf(root):\n",
    "    token_ids = {t.attrib[\"ID\"]: t.text for t in root.find('tc:TextCorpus', ns).find('tc:tokens', ns)}\n",
    "    pos_tags = {t.attrib[\"tokenIDs\"]: t.text for t in root.find('tc:TextCorpus', ns).find('tc:POStags', ns)}\n",
    "    return [[(token_ids[id], pos_tags[id]) for id in sent.attrib['tokenIDs'].split(\" \")] for sent in root.find('tc:TextCorpus', ns).find('tc:sentences', ns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_from_url(url):\n",
    "    # Get the file name of the url.\n",
    "    path = urllib.parse.urlparse(url)\n",
    "    _, filename = os.path.split(path.path)\n",
    "    filename += \".xml\"\n",
    "    # Check if sentence file is cached.\n",
    "    if os.path.isfile(filename):\n",
    "        logging.info(f\"reading from cache: {filename}\")\n",
    "        with open(filename) as f:\n",
    "            return f.read()\n",
    "    # Download file.\n",
    "    logging.debug(f\"downloading from url: {url}\")\n",
    "    with urllib.request.urlopen(url) as f:\n",
    "        contents = f.read()    \n",
    "    logging.info(f\"caching to file: {filename}\")    \n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(contents)\n",
    "    return contents\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def read_sentences_from_url(url):\n",
    "    # Get the file name of the url.\n",
    "    path = urllib.parse.urlparse(url)\n",
    "    _, filename = os.path.split(path.path)\n",
    "    filename += \".sents.txt\"\n",
    "    # Check if sentence file is cached.\n",
    "    if os.path.isfile(filename):\n",
    "        print(f\"reading from cache: {filename}\")\n",
    "        with open(filename) as f:\n",
    "            # Read sentences from the cached file.\n",
    "            return [[nltk.str2tuple(t) for t in sent[:-1].split(\" \")] for sent in f.readlines()]\n",
    "\n",
    "    # File is not cached; download it and cache it.\n",
    "    sents = tags_from_tcf(ET.fromstring(read_xml_from_url(url)))\n",
    "    print(f\"caching to file: {filename}\")    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for sent in sents:\n",
    "            f.write(\" \".join([t[0] + \"/\" + t[1] for t in sent]))\n",
    "            f.write(\"\\n\")\n",
    "    # Return sentences.\n",
    "    return sents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of sentences: 42269\n"
     ]
    }
   ],
   "source": [
    "tagged_sents = [sent for url in urls for sent in read_sentences_from_url(url)]\n",
    "print(\"number of sentences:\", len(tagged_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test set:  4227\ntrain set: 38042\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(13)\n",
    "random.shuffle(tagged_sents)\n",
    "size = int(len(tagged_sents) * 0.9)\n",
    "test_sents = tagged_sents[size:]\n",
    "train_sents = tagged_sents[:size]\n",
    "print(\"test set: \", len(test_sents))\n",
    "print(\"train set:\", len(train_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9381128823782853"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokens:  ['Hierzu', 'noch', 'einige', 'Erläuterungen', '.']\nindex:   0\nhistory: []\ntokens:  ['Hierzu', 'noch', 'einige', 'Erläuterungen', '.']\nindex:   1\nhistory: ['NN']\ntokens:  ['Hierzu', 'noch', 'einige', 'Erläuterungen', '.']\nindex:   2\nhistory: ['NN', 'NN']\ntokens:  ['Hierzu', 'noch', 'einige', 'Erläuterungen', '.']\nindex:   3\nhistory: ['NN', 'NN', 'NN']\ntokens:  ['Hierzu', 'noch', 'einige', 'Erläuterungen', '.']\nindex:   4\nhistory: ['NN', 'NN', 'NN', 'NN']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "class LogTagger(nltk.tag.sequential.SequentialBackoffTagger):\n",
    "    def __init__(self, backoff=None):\n",
    "        super().__init__(backoff)\n",
    "\n",
    "    def choose_tag(self, tokens, index, history):\n",
    "        print(\"tokens: \", tokens)\n",
    "        print(\"index:  \", index)\n",
    "        print(\"history:\", history)\n",
    "        return None \n",
    "\n",
    "for sent in test_sents:\n",
    "    if len(sent) == 5:\n",
    "        short_sent = sent \n",
    "\n",
    "tx = LogTagger(backoff=t0)\n",
    "tx.evaluate([short_sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:TreeTagger:Abbreviation file not found: german-abbreviations-utf8\n",
      "WARNING:TreeTagger:Processing without abbreviations file.\n",
      "ERROR:TreeTagger:Time out for TreeTagger reply.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TreeTaggerError",
     "evalue": "Time out for TreeTagger reply, enable debug / see error logs",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTreeTaggerError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e233d7ecfded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeTaggerX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'de'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../08/tree-tagger'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages/nltk/tag/api.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, gold)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \"\"\"\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtagged_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muntag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mgold_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtest_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages/nltk/tag/api.py\u001b[0m in \u001b[0;36mtag_sents\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages/nltk/tag/api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages/nltk/tag/sequential.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages/nltk/tag/sequential.py\u001b[0m in \u001b[0;36mtag_one\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_taggers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e233d7ecfded>\u001b[0m in \u001b[0;36mchoose_tag\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchoose_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtripple2tupple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtripple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtripple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/work/kb21/jupyter/venv/lib/python3.7/site-packages/treetaggerwrapper.py\u001b[0m in \u001b[0;36mtag_text\u001b[0;34m(self, text, numlines, tagonly, prepronly, tagblanks, notagurl, notagemail, notagip, notagdns, nosgmlsplit)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                         \u001b[0;31m# process communication. This avoid infinite loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m                         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time out for TreeTagger reply.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mTreeTaggerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time out for TreeTagger reply, enable debug / see error logs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1452\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                         \u001b[0;31m# We process too much quickly, leave time for tagger and writer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTreeTaggerError\u001b[0m: Time out for TreeTagger reply, enable debug / see error logs"
     ]
    }
   ],
   "source": [
    "def tripple2tupple(str):\n",
    "    tmp = str.split(\"\\t\")\n",
    "    return (tmp[0], tmp[1])\n",
    "\n",
    "class TreeTaggerX(nltk.tag.sequential.SequentialBackoffTagger):\n",
    "    def __init__(self, language, directory, backoff=None):\n",
    "        super().__init__(backoff)\n",
    "        self.tagger = TTW.TreeTagger(TAGLANG=language, TAGDIR=directory)\n",
    "        self.tags = None\n",
    "\n",
    "    def choose_tag(self, tokens, index, history):\n",
    "        if index == 0:\n",
    "            self.tags = [tripple2tupple(tripple) for tripple in self.tagger.tag_text(\" \".join(tokens))]\n",
    "        if index < len(self.tags):\n",
    "            return self.tags[index][1]\n",
    "        return None \n",
    "       \n",
    "tt = TreeTaggerX('de', '../08/tree-tagger', t0)\n",
    "tt.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:TreeTagger:Abbreviation file not found: german-abbreviations-utf8\n",
      "WARNING:TreeTagger:Processing without abbreviations file.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7903317535545024"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "class TreeTagger(nltk.tag.sequential.SequentialBackoffTagger):\n",
    "    def __init__(self, language, directory, backoff=None):\n",
    "        super().__init__(backoff)\n",
    "        self.tagger = TTW.TreeTagger(TAGLANG=language, TAGDIR=directory, TAGOPT='-token -sgml -quiet')\n",
    "        self.tags = None\n",
    "\n",
    "    def choose_tag(self, tokens, index, history):\n",
    "        if index == 0:\n",
    "            self.tags = [tripple2tupple(tripple) for tripple in self.tagger.tag_text(\" \".join(tokens))]\n",
    "        if index < len(self.tags):\n",
    "            return self.tags[index][1]\n",
    "        return None\n",
    "tt = TreeTagger('de', '../08/tree-tagger', t0)\n",
    "tt.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:TreeTagger:Abbreviation file not found: german-abbreviations-utf8\n",
      "WARNING:TreeTagger:Processing without abbreviations file.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7903317535545024"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "tt = TreeTagger('de', '../08/tree-tagger', t2)\n",
    "tt.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:TreeTagger:Abbreviation file not found: german-abbreviations-utf8\n",
      "WARNING:TreeTagger:Processing without abbreviations file.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8316415338216286"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "tt = TreeTagger('de', '../08/tree-tagger', t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=tt)\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.886370569214813"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "url='https://www.deutschestextarchiv.de/book/download_fulltcf/34066'\n",
    "tagged_sents = read_sentences_from_url(url)\n",
    "\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t2.evaluate(tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:TreeTagger:Abbreviation file not found: german-abbreviations-utf8\n",
      "WARNING:TreeTagger:Processing without abbreviations file.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8629125739735221"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "tt = TreeTagger('de', '../08/tree-tagger', t0)\n",
    "tt.evaluate(tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9168110918544194"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "url = 'https://www.deutschestextarchiv.de/book/download_fulltcf/32274'\n",
    "tagged_sents = read_sentences_from_url(url)\n",
    "t2.evaluate(tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9410745233968805"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "tt.evaluate(tagged_sents)"
   ]
  }
 ]
}